
#+TITLE: BSC HPC: MareNostrum 5 Quickstart

* Introduction

This document is a
quickstart guide for MareNostrum 5 (MN5). You can find the
official documentation of the BSC's HPC enviroment [[https://www.bsc.es/supportkc/][here]]. 

* System overview

The computational nodes of MN5 belong to two groups: General Purpose
Partition (GPP) and Accelerated Partition (ACC). The latter being
fitted with GPU's. These are separate partitions, meaning the
available environments, (e.g., python modules), may be different.
All nodes have acces to the General Parallel File System (GPFS). 

* Login and transfer nodes

Jobs can be submitted to the computational nodes and data transfered
to the GPFS via login-nodes and transfer-nodes, respectively. The
login-nodes and transfer-nodes are accessible from outside the
BSC. These nodes not access the outside for security reasons.

|---------------+------------------+-----------|
| Node type     | Node             | Partition |
|---------------+------------------+-----------|
| Login         | glogin1.bsc.es.  | GPP       |
|               | glogin2.bsc.es   | GPP       |
|---------------+------------------+-----------|
| Login         | alogin1.bsc.es   | ACC       |
|               | alogin2.bsc.es   | ACC       |
|---------------+------------------+-----------|
| Data transfer | transfer1.bsc.es | shared    |
|               | transfer2.bsc.es | shared    |
|               | transfer3.bsc.es | shared    |
|               | transfer4.bsc.es | shared    |
|---------------+------------------+-----------|
* Login

You can log in into one of the login and transfer nodes using ssh:

#+BEGIN_SRC
mylaptop$> ssh <username>@glogin1.bsc.es
mylaptop$> ssh <username>@alogin1.bsc.es
mylaptop$> ssh <username>@transfer1.bsc.es
#+END_SRC

To avoid being prompted for your password each time, you can setup a passkey, instructions [[https://wiki.archlinux.org/title/SSH_keys][here]].  

* GPFS

The GPFS is a global file system, accessible from both the GPP and ACC
nodes. There is project data storage space available 
~/gpfs/project/<GROUP>~.  In the case of ICONBI, the group is
bsc79. Note that the storage quota is shared amonst the research
group. Tou can check current usage running ~bsc_quota~.

* Computational environment (modules)

The Environment Module package is used to load software and libraries via modules.

To list all currently loaded modules:

#+begin_src bash
module list
#+end_src

To list all available modules:
#+begin_src bash
module avail
#+end_src

To list all available modules starting with <string>:
#+begin_src bash
module avail <string>
#+end_src


To load a module:
#+begin_src bash
 module  load <module name>
#+end_src

For instance, to load python on GPP:
#+begin_src bash
 module  load python/3.12.1
#+end_src

Ofcourse, for more detail on the module system, read the man pages:
#+begin_src bash
 man module
#+end_src
